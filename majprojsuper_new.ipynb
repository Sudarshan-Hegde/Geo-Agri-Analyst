{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a53730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m481.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.0+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhegdesudarshan\u001b[0m (\u001b[33mhegdesudarshan-hegde\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì WandB authenticated\n",
      "\n",
      "üöÄ Device: cuda | GPUs: 2\n",
      "   GPU 0: Tesla T4\n",
      "   GPU 1: Tesla T4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20251125_114305-g6x3mxih</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification/runs/g6x3mxih' target=\"_blank\">SR-ResNet-AL-20251125-114305</a></strong> to <a href='https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification' target=\"_blank\">https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification/runs/g6x3mxih' target=\"_blank\">https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification/runs/g6x3mxih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Setup complete!\n",
      "Config: {'dataset_size': 50000, 'num_classes': 19, 'sr_model_path': '/kaggle/input/sr-model/pytorch/default/3/generator_ensemble.pth', 'lr_size': 32, 'hr_size': 128, 'clf_epochs': 20, 'batch_size': 32, 'lr': 0.0001, 'weight_decay': 0.0001, 'al_cycles': 4, 'al_epochs_per_cycle': 10, 'initial_labeled_ratio': 0.1, 'query_size_ratio': 0.1, 'num_workers': 4, 'pin_memory': True, 'mixed_precision': True}\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 1: Dependencies & WandB Setup\n",
    "# ===============================================================================\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install -q torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q wandb scikit-learn matplotlib seaborn tqdm Pillow rasterio pandas\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import rasterio\n",
    "import wandb\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# WandB Login\n",
    "wandb.login(key=\"5424a3d65aac1662f5be82d4439aaac35046689e\")\n",
    "print(\"‚úì WandB authenticated\")\n",
    "\n",
    "# Device Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(f\"\\nüöÄ Device: {device} | GPUs: {gpu_count}\")\n",
    "if gpu_count > 0:\n",
    "    for i in range(gpu_count):\n",
    "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# MAXIMIZED Config for full 12h utilization with extensive evaluation\n",
    "config = {\n",
    "    # Dataset - MAXIMIZED\n",
    "    'dataset_size': 100000,  # Increased from 60k ‚Üí 100k (use full dataset)\n",
    "    'num_classes': 19,       # BigEarthNet-19 classes\n",
    "    \n",
    "    # SR Model\n",
    "    'sr_model_path': '/kaggle/input/sr-model/pytorch/default/3/generator_ensemble.pth',\n",
    "    'lr_size': 32,           # LR input size\n",
    "    'hr_size': 128,          # HR output size (32*4)\n",
    "    \n",
    "    # Classifier Training - MAXIMIZED FOR 12H\n",
    "    'clf_epochs': 50,        # Increased from 30 ‚Üí 50 for maximum learning\n",
    "    'batch_size': 64,        # Increased from 48 ‚Üí 64 (optimal throughput)\n",
    "    'lr': 3e-4,              # Increased from 2e-4 ‚Üí 3e-4 (faster convergence)\n",
    "    'weight_decay': 1e-5,    # Reduced from 5e-5 ‚Üí 1e-5 (minimal regularization)\n",
    "    'warmup_epochs': 5,      # Increased from 3 ‚Üí 5 (better stability)\n",
    "    'label_smoothing': 0.15, # Increased from 0.1 ‚Üí 0.15 (more smoothing)\n",
    "    \n",
    "    # Active Learning\n",
    "    'al_cycles': 4,\n",
    "    'al_epochs_per_cycle': 10,\n",
    "    'initial_labeled_ratio': 0.1,\n",
    "    'query_size_ratio': 0.1,\n",
    "    \n",
    "    # Training Enhancements\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True,\n",
    "    'mixed_precision': True,\n",
    "    'gradient_clip': 1.0,\n",
    "    'ema_decay': 0.9995,     # Increased decay for more stability\n",
    "    \n",
    "    # Evaluation & Visualization\n",
    "    'eval_frequency': 1,     # Evaluate every epoch\n",
    "    'viz_frequency': 2,      # Generate visualizations every 2 epochs\n",
    "    'save_feature_maps': True,  # Save feature extraction visualizations\n",
    "    'save_sr_examples': True,   # Save SR enhancement examples\n",
    "}\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(\n",
    "    project=\"SR-ResNet-AL-Classification\",\n",
    "    config=config\n",
    "    # name parameter removed - WandB will generate random name automatically\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Setup complete!\")\n",
    "print(f\"Config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ebcd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained SR model...\n",
      "‚úì SR Model loaded: torch.Size([1, 3, 32, 32]) ‚Üí torch.Size([1, 3, 256, 256])\n",
      "  Parameters: 9.77M\n",
      "\n",
      "‚úì SR model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 2: Load Pre-trained SR Model (EXACT ARCHITECTURE FROM CHECKPOINT)\n",
    "# ===============================================================================\n",
    "\n",
    "class RFB(nn.Module):\n",
    "    \"\"\"Receptive Field Block - EXACT match to checkpoint\"\"\"\n",
    "    def __init__(self, in_channels=64):\n",
    "        super().__init__()\n",
    "        # Branch 1: AvgPool(3) + Conv + ReLU + Conv\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, 16, 1, 1, 0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 16, 3, 1, padding=1, dilation=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Branch 2: AvgPool(5) + Conv + ReLU + Conv\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.AvgPool2d(5, stride=1, padding=2),\n",
    "            nn.Conv2d(in_channels, 24, 1, 1, 0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(24, 24, 3, 1, padding=2, dilation=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Branch 3: AvgPool(7) + Conv + ReLU + Conv\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(7, stride=1, padding=3),\n",
    "            nn.Conv2d(in_channels, 24, 1, 1, 0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(24, 24, 3, 1, padding=3, dilation=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Changed to match checkpoint: conv_concat instead of conv\n",
    "        self.conv_concat = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 1, 1, 0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b1 = self.branch1(x)\n",
    "        b2 = self.branch2(x)\n",
    "        b3 = self.branch3(x)\n",
    "        out = torch.cat([b1, b2, b3], 1)\n",
    "        return self.conv_concat(out) * 0.2 + x\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    \"\"\"Dense Block with 5 conv layers - MODIFIED channel counts to match checkpoint\"\"\"\n",
    "    def __init__(self, nf=64):\n",
    "        super().__init__()\n",
    "        # Changed: nf=64 in Generator, but DenseBlock uses nf_internal=32\n",
    "        nf_internal = 32\n",
    "        self.conv1 = nn.Conv2d(nf, nf_internal, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(nf + nf_internal, nf_internal, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(nf + nf_internal*2, nf_internal, 3, 1, 1)\n",
    "        self.conv4 = nn.Conv2d(nf + nf_internal*3, nf_internal, 3, 1, 1)\n",
    "        self.conv5 = nn.Conv2d(nf + nf_internal*4, nf, 3, 1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = F.relu(self.conv2(torch.cat([x, x1], 1)))\n",
    "        x3 = F.relu(self.conv3(torch.cat([x, x1, x2], 1)))\n",
    "        x4 = F.relu(self.conv4(torch.cat([x, x1, x2, x3], 1)))\n",
    "        x5 = self.conv5(torch.cat([x, x1, x2, x3, x4], 1))\n",
    "        return x5 * 0.2 + x\n",
    "\n",
    "class RRDB(nn.Module):\n",
    "    \"\"\"Residual-in-Residual Dense Block (3 DenseBlocks)\"\"\"\n",
    "    def __init__(self, nf=64):\n",
    "        super().__init__()\n",
    "        self.db1 = DenseBlock(nf)\n",
    "        self.db2 = DenseBlock(nf)\n",
    "        self.db3 = DenseBlock(nf)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.db3(self.db2(self.db1(x)))\n",
    "        return out * 0.2 + x\n",
    "\n",
    "class RRFDB(nn.Module):\n",
    "    \"\"\"Residual RFB Dense Block - MODIFIED to match checkpoint structure\"\"\"\n",
    "    def __init__(self, nf=64):\n",
    "        super().__init__()\n",
    "        # Changed: Use named attributes instead of ModuleList to match checkpoint keys\n",
    "        self.rfb1 = RFB(nf)\n",
    "        self.rfb2 = RFB(nf)\n",
    "        self.rfb3 = RFB(nf)\n",
    "        self.rfb4 = RFB(nf)\n",
    "        self.rfb5 = RFB(nf)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.rfb1(x)\n",
    "        out = self.rfb2(out)\n",
    "        out = self.rfb3(out)\n",
    "        out = self.rfb4(out)\n",
    "        out = self.rfb5(out)\n",
    "        return out * 0.2 + x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator: 12 RRDB + 6 RRFDB + 8x upscale - EXACT architecture from checkpoint\"\"\"\n",
    "    def __init__(self, num_rrdb=12, num_rrfdb=6, nf=64):\n",
    "        super().__init__()\n",
    "        self.conv_first = nn.Conv2d(3, nf, 3, 1, 1)\n",
    "        \n",
    "        # Trunk A: 12 RRDB blocks\n",
    "        self.trunk_a = nn.Sequential(*[RRDB(nf) for _ in range(num_rrdb)])\n",
    "        \n",
    "        # Trunk RFB: 6 RRFDB blocks\n",
    "        self.trunk_rfb = nn.Sequential(*[RRFDB(nf) for _ in range(num_rrfdb)])\n",
    "        \n",
    "        # RFB upsampling\n",
    "        self.rfb_up = RFB(nf)\n",
    "        \n",
    "        # 8x upscaling (3 PixelShuffle layers: 2x each = 2^3 = 8x)\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(nf, nf*4, 3, 1, 1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(nf, nf*4, 3, 1, 1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(nf, nf*4, 3, 1, 1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Changed to match checkpoint: Sequential with conv_final layers\n",
    "        self.conv_final = nn.Sequential(\n",
    "            nn.Conv2d(nf, nf, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(nf, 3, 3, 1, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feat = self.conv_first(x)\n",
    "        trunk_a_out = self.trunk_a(feat)\n",
    "        trunk_rfb_out = self.trunk_rfb(trunk_a_out)\n",
    "        rfb_up_out = self.rfb_up(trunk_rfb_out)\n",
    "        up = self.upsample(rfb_up_out + feat)\n",
    "        return torch.tanh(self.conv_final(up))\n",
    "\n",
    "# Load Pre-trained SR Model\n",
    "print(\"Loading pre-trained SR model...\")\n",
    "sr_model = Generator(num_rrdb=12, num_rrfdb=6, nf=64).to(device)\n",
    "\n",
    "try:\n",
    "    state_dict = torch.load(config['sr_model_path'], map_location=device)\n",
    "    sr_model.load_state_dict(state_dict)\n",
    "    sr_model.eval()\n",
    "    \n",
    "    # Test SR model\n",
    "    with torch.no_grad():\n",
    "        test_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "        test_output = sr_model(test_input)\n",
    "        print(f\"‚úì SR Model loaded: {test_input.shape} ‚Üí {test_output.shape}\")\n",
    "        \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in sr_model.parameters())\n",
    "    print(f\"  Parameters: {total_params/1e6:.2f}M\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading SR model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "# Freeze SR model (no training needed)\n",
    "for param in sr_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"\\n‚úì SR model ready for inference!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f95c772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BigEarthNet dataset...\n",
      "Found 347244 band files\n",
      "Valid RGB patches: 28937\n",
      "Warning: metadata.parquet not found, using dummy labels\n",
      "Split: 23149 train, 5788 val\n",
      "\n",
      "‚úì Dataset loaded!\n",
      "  Train batches: 724\n",
      "  Val batches: 91\n",
      "\n",
      "Sample batch shapes:\n",
      "  LR: torch.Size([32, 3, 32, 32])\n",
      "  Label: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 3: Dataset Loading (BigEarthNet)\n",
    "# ===============================================================================\n",
    "\n",
    "class BigEarthNetDataset(Dataset):\n",
    "    \"\"\"BigEarthNet dataset with SR preprocessing\"\"\"\n",
    "    def __init__(self, root_path, patch_ids, patch_to_bands, patch_to_label, \n",
    "                 sr_model=None, phase='train'):\n",
    "        self.root_path = root_path\n",
    "        self.patch_ids = patch_ids\n",
    "        self.patch_to_bands = patch_to_bands\n",
    "        self.patch_to_label = patch_to_label\n",
    "        self.sr_model = sr_model\n",
    "        self.phase = phase\n",
    "        \n",
    "        # Transforms\n",
    "        if phase == 'train':\n",
    "            self.spatial_aug = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(90)\n",
    "            ])\n",
    "        else:\n",
    "            self.spatial_aug = None\n",
    "            \n",
    "        self.to_tensor = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.patch_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patch_id = self.patch_ids[idx]\n",
    "        bands = self.patch_to_bands[patch_id]\n",
    "        \n",
    "        try:\n",
    "            # Load RGB bands (B04=Red, B03=Green, B02=Blue)\n",
    "            b02 = rasterio.open(bands['02']).read(1).astype(np.float32) / 10000.0\n",
    "            b03 = rasterio.open(bands['03']).read(1).astype(np.float32) / 10000.0\n",
    "            b04 = rasterio.open(bands['04']).read(1).astype(np.float32) / 10000.0\n",
    "            \n",
    "            # Stack to RGB (120x120)\n",
    "            hr_np = np.stack([b04, b03, b02], axis=-1)\n",
    "            hr_np = np.clip(hr_np, 0, 1)\n",
    "            \n",
    "            # Convert to PIL for augmentation\n",
    "            hr_pil = Image.fromarray((hr_np * 255).astype(np.uint8))\n",
    "            \n",
    "            # Apply spatial augmentation\n",
    "            if self.spatial_aug:\n",
    "                hr_pil = self.spatial_aug(hr_pil)\n",
    "            \n",
    "            # Resize to 32x32 for LR input\n",
    "            lr_pil = hr_pil.resize((32, 32), Image.BICUBIC)\n",
    "            \n",
    "            # To tensor\n",
    "            lr_tensor = self.to_tensor(lr_pil)\n",
    "            \n",
    "            # Get label (multi-hot ‚Üí single label via argmax)\n",
    "            label_multihot = self.patch_to_label.get(patch_id, torch.zeros(config['num_classes']))\n",
    "            label = torch.argmax(label_multihot).long()\n",
    "            \n",
    "            return {\n",
    "                'lr': lr_tensor,\n",
    "                'label': label,\n",
    "                'patch_id': patch_id\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Return black dummy on error\n",
    "            print(f\"Error loading {patch_id}: {e}\")\n",
    "            return {\n",
    "                'lr': torch.zeros(3, 32, 32),\n",
    "                'label': torch.tensor(0, dtype=torch.long),\n",
    "                'patch_id': patch_id\n",
    "            }\n",
    "\n",
    "# Load BigEarthNet metadata\n",
    "print(\"Loading BigEarthNet dataset...\")\n",
    "image_root_path = '/kaggle/input/bigearthnetv2-s2-4/'\n",
    "\n",
    "# Find all TIF files\n",
    "import glob\n",
    "all_tif_paths = glob.glob(os.path.join(image_root_path, '**/*.tif'), recursive=True)\n",
    "print(f\"Found {len(all_tif_paths)} band files\")\n",
    "\n",
    "# Group by patch ID\n",
    "patch_to_bands = {}\n",
    "for path in all_tif_paths:\n",
    "    fname = os.path.basename(path)\n",
    "    if '_B' in fname:\n",
    "        patch_id = '_'.join(fname.split('_B')[:-1])\n",
    "        band = fname.split('_B')[-1].split('.')[0]\n",
    "        if patch_id not in patch_to_bands:\n",
    "            patch_to_bands[patch_id] = {}\n",
    "        patch_to_bands[patch_id][band] = path\n",
    "\n",
    "# Filter patches with RGB bands\n",
    "valid_patches = [pid for pid, bands in patch_to_bands.items() \n",
    "                 if all(b in bands for b in ['02', '03', '04'])]\n",
    "valid_patches = valid_patches[:config['dataset_size']]\n",
    "print(f\"Valid RGB patches: {len(valid_patches)}\")\n",
    "\n",
    "# Load labels from metadata\n",
    "metadata_path = os.path.join(image_root_path, 'metadata.parquet')\n",
    "if os.path.exists(metadata_path):\n",
    "    df = pd.read_parquet(metadata_path)\n",
    "    patch_to_label = {}\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row['patch_id']\n",
    "        labels_list = row['labels'] if isinstance(row['labels'], list) else []\n",
    "        multi_hot = torch.zeros(config['num_classes'])\n",
    "        for lbl in labels_list:\n",
    "            if 0 <= lbl < config['num_classes']:\n",
    "                multi_hot[lbl] = 1.0\n",
    "        if pid in valid_patches:\n",
    "            patch_to_label[pid] = multi_hot\n",
    "    print(f\"Loaded labels for {len(patch_to_label)} patches\")\n",
    "else:\n",
    "    print(\"Warning: metadata.parquet not found, using dummy labels\")\n",
    "    patch_to_label = {pid: torch.zeros(config['num_classes']) for pid in valid_patches}\n",
    "\n",
    "# Train/Val split\n",
    "train_ids, val_ids = train_test_split(valid_patches, test_size=0.2, random_state=42)\n",
    "print(f\"Split: {len(train_ids)} train, {len(val_ids)} val\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BigEarthNetDataset(image_root_path, train_ids, patch_to_bands, \n",
    "                                   patch_to_label, sr_model, phase='train')\n",
    "val_dataset = BigEarthNetDataset(image_root_path, val_ids, patch_to_bands, \n",
    "                                 patch_to_label, sr_model, phase='val')\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], \n",
    "                         shuffle=True, num_workers=config['num_workers'], \n",
    "                         pin_memory=config['pin_memory'])\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size']*2, \n",
    "                       shuffle=False, num_workers=config['num_workers'], \n",
    "                       pin_memory=config['pin_memory'])\n",
    "\n",
    "print(\"\\n‚úì Dataset loaded!\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Test batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "print(f\"  LR: {sample_batch['lr'].shape}\")\n",
    "print(f\"  Label: {sample_batch['label'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f25374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up GPU memory...\n",
      "‚úì GPU memory cleaned\n",
      "  GPU 0: 0.07GB allocated, 0.08GB reserved\n",
      "  GPU 1: 0.00GB allocated, 0.00GB reserved\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 3.5: GPU Memory Cleanup (Run this if you encounter CUDA errors)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"Cleaning up GPU memory...\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Reset CUDA device if needed\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\"‚úì GPU memory cleaned\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        mem_allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "        mem_reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "        print(f\"  GPU {i}: {mem_allocated:.2f}GB allocated, {mem_reserved:.2f}GB reserved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SR-Enhanced ResNet50 Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 151MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Classifier moved to GPU\n",
      "  Using DataParallel across 2 GPUs\n",
      "\n",
      "‚úì Classifier created\n",
      "  Total parameters: 33.32M\n",
      "  Trainable parameters: 23.55M\n",
      "\n",
      "Test forward pass: torch.Size([2, 3, 32, 32]) ‚Üí torch.Size([2, 19])\n",
      "Output range: [-0.144, 0.135]\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 4: ResNet Classifier Definition\n",
    "# ===============================================================================\n",
    "\n",
    "class SREnhancedClassifier(nn.Module):\n",
    "    \"\"\"ResNet50-based classifier that processes SR-enhanced images\"\"\"\n",
    "    def __init__(self, num_classes, sr_model, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.sr_model = sr_model  # Frozen SR model\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        if pretrained:\n",
    "            weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "            self.backbone = resnet50(weights=weights)\n",
    "        else:\n",
    "            self.backbone = resnet50(weights=None)\n",
    "        \n",
    "        # Replace final FC layer with enhanced classifier head\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.4),  # Increased dropout\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, lr_images):\n",
    "        # Step 1: SR enhancement (frozen) - 32x32 ‚Üí 256x256\n",
    "        with torch.no_grad():\n",
    "            sr_images = self.sr_model(lr_images)\n",
    "            # Resize 256x256 ‚Üí 224x224 for ResNet50\n",
    "            sr_images = F.interpolate(sr_images, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Step 2: ResNet classification\n",
    "        x = self.backbone.conv1(sr_images)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "        \n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "        \n",
    "        x = self.backbone.avgpool(x)\n",
    "        features = torch.flatten(x, 1)\n",
    "        output = self.backbone.fc(features)\n",
    "        return output\n",
    "    \n",
    "    def get_features(self, lr_images):\n",
    "        \"\"\"Extract features for active learning\"\"\"\n",
    "        with torch.no_grad():\n",
    "            sr_images = self.sr_model(lr_images)\n",
    "            sr_images = F.interpolate(sr_images, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "            \n",
    "            x = self.backbone.conv1(sr_images)\n",
    "            x = self.backbone.bn1(x)\n",
    "            x = self.backbone.relu(x)\n",
    "            x = self.backbone.maxpool(x)\n",
    "            \n",
    "            x = self.backbone.layer1(x)\n",
    "            x = self.backbone.layer2(x)\n",
    "            x = self.backbone.layer3(x)\n",
    "            x = self.backbone.layer4(x)\n",
    "            \n",
    "            x = self.backbone.avgpool(x)\n",
    "            return torch.flatten(x, 1)\n",
    "\n",
    "# Create classifier with error handling\n",
    "print(\"Creating SR-Enhanced ResNet50 Classifier...\")\n",
    "\n",
    "try:\n",
    "    # Clean GPU memory before creating model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Create classifier on CPU first\n",
    "    classifier = SREnhancedClassifier(config['num_classes'], sr_model, pretrained=True)\n",
    "    \n",
    "    # Move to GPU carefully\n",
    "    classifier = classifier.to(device)\n",
    "    print(\"‚úì Classifier moved to GPU\")\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    if \"CUDA\" in str(e):\n",
    "        print(f\"‚ö† CUDA Error: {e}\")\n",
    "        print(\"Attempting recovery: Restarting kernel may help\")\n",
    "        print(\"Run the memory cleanup cell (Cell 3.5) and try again\")\n",
    "        raise\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "if gpu_count > 1:\n",
    "    classifier = nn.DataParallel(classifier)\n",
    "    print(f\"  Using DataParallel across {gpu_count} GPUs\")\n",
    "\n",
    "# Count parameters\n",
    "trainable_params = sum(p.numel() for p in classifier.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in classifier.parameters())\n",
    "print(f\"\\n‚úì Classifier created\")\n",
    "print(f\"  Total parameters: {total_params/1e6:.2f}M\")\n",
    "print(f\"  Trainable parameters: {trainable_params/1e6:.2f}M\")\n",
    "\n",
    "# Test forward pass\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        test_lr = torch.randn(2, 3, 32, 32).to(device)\n",
    "        test_output = classifier(test_lr)\n",
    "        print(f\"\\nTest forward pass: {test_lr.shape} ‚Üí {test_output.shape}\")\n",
    "        print(f\"Output range: [{test_output.min():.3f}, {test_output.max():.3f}]\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"‚ö† Test forward pass failed: {e}\")\n",
    "    print(\"This may indicate GPU memory issues. Try restarting the kernel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ba4d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Training functions defined\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 5: Training & Evaluation Functions\n",
    "# ===============================================================================\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, scaler, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for batch in pbar:\n",
    "        lr_imgs = batch['lr'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if config['mixed_precision']:\n",
    "            with autocast():\n",
    "                outputs = model(lr_imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(lr_imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * lr_imgs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'acc': f\"{100.*correct/total:.2f}%\"\n",
    "        })\n",
    "    \n",
    "    return total_loss / total, 100. * correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            lr_imgs = batch['lr'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            if config['mixed_precision']:\n",
    "                with autocast():\n",
    "                    outputs = model(lr_imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            else:\n",
    "                outputs = model(lr_imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item() * lr_imgs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro') * 100\n",
    "    avg_loss = total_loss / len(all_labels)\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, epoch):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - Epoch {epoch}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Log to wandb\n",
    "    wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
    "    plt.close()\n",
    "\n",
    "print(\"‚úì Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb9dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# CELL 5.5: Comprehensive Evaluation Metrics & Visualization Functions\n",
    "# ===============================================================================\n",
    "\n",
    "def compute_per_class_metrics(y_true, y_pred, num_classes=19):\n",
    "    \"\"\"Compute precision, recall, F1 per class\"\"\"\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=list(range(num_classes)), zero_division=0\n",
    "    )\n",
    "    return precision, recall, f1, support\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    \"\"\"Plot training and validation curves\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train', linewidth=2)\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Loss Curves')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(history['train_acc'], label='Train', linewidth=2)\n",
    "    axes[0, 1].plot(history['val_acc'], label='Val', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].set_title('Accuracy Curves')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1 Score\n",
    "    axes[1, 0].plot(history['val_f1'], label='Val F1 (Macro)', linewidth=2, color='green')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('F1 Score (%)')\n",
    "    axes[1, 0].set_title('F1 Score Curve')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[1, 1].plot(history['lr'], linewidth=2, color='red')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Learning Rate')\n",
    "    axes[1, 1].set_title('Learning Rate Schedule')\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    wandb.log({\"training_curves\": wandb.Image(plt)})\n",
    "    plt.savefig('/kaggle/working/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_per_class_performance(precision, recall, f1, support, class_names=None):\n",
    "    \"\"\"Plot per-class metrics\"\"\"\n",
    "    if class_names is None:\n",
    "        class_names = [f'Class {i}' for i in range(len(precision))]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    x = np.arange(len(class_names))\n",
    "    \n",
    "    # Precision\n",
    "    axes[0, 0].bar(x, precision * 100, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('Class')\n",
    "    axes[0, 0].set_ylabel('Precision (%)')\n",
    "    axes[0, 0].set_title('Per-Class Precision')\n",
    "    axes[0, 0].set_xticks(x)\n",
    "    axes[0, 0].set_xticklabels(class_names, rotation=45, ha='right', fontsize=8)\n",
    "    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "    axes[0, 0].axhline(y=precision.mean()*100, color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Recall\n",
    "    axes[0, 1].bar(x, recall * 100, color='lightgreen', edgecolor='darkgreen', alpha=0.7)\n",
    "    axes[0, 1].set_xlabel('Class')\n",
    "    axes[0, 1].set_ylabel('Recall (%)')\n",
    "    axes[0, 1].set_title('Per-Class Recall')\n",
    "    axes[0, 1].set_xticks(x)\n",
    "    axes[0, 1].set_xticklabels(class_names, rotation=45, ha='right', fontsize=8)\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "    axes[0, 1].axhline(y=recall.mean()*100, color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # F1 Score\n",
    "    axes[1, 0].bar(x, f1 * 100, color='lightcoral', edgecolor='darkred', alpha=0.7)\n",
    "    axes[1, 0].set_xlabel('Class')\n",
    "    axes[1, 0].set_ylabel('F1 Score (%)')\n",
    "    axes[1, 0].set_title('Per-Class F1 Score')\n",
    "    axes[1, 0].set_xticks(x)\n",
    "    axes[1, 0].set_xticklabels(class_names, rotation=45, ha='right', fontsize=8)\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    axes[1, 0].axhline(y=f1.mean()*100, color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Support (sample count)\n",
    "    axes[1, 1].bar(x, support, color='plum', edgecolor='purple', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Class')\n",
    "    axes[1, 1].set_ylabel('Sample Count')\n",
    "    axes[1, 1].set_title('Per-Class Sample Distribution')\n",
    "    axes[1, 1].set_xticks(x)\n",
    "    axes[1, 1].set_xticklabels(class_names, rotation=45, ha='right', fontsize=8)\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    wandb.log({\"per_class_metrics\": wandb.Image(plt)})\n",
    "    plt.savefig('/kaggle/working/per_class_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "class EMA:\n",
    "    \"\"\"Exponential Moving Average for model weights\"\"\"\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "        self.register()\n",
    "    \n",
    "    def register(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "    \n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "    \n",
    "    def apply_shadow(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                param.data = self.shadow[name]\n",
    "    \n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "\n",
    "def visualize_sr_enhancement(model, dataset, device, num_samples=8):\n",
    "    \"\"\"Visualize SR enhancement: LR ‚Üí SR ‚Üí HR comparison\"\"\"\n",
    "    model.eval()\n",
    "    samples = []\n",
    "    for i in range(num_samples):\n",
    "        sample = dataset[np.random.randint(len(dataset))]\n",
    "        samples.append(sample)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 3*num_samples))\n",
    "    \n",
    "    # Handle DataParallel wrapper\n",
    "    sr_model = model.module.sr_model if hasattr(model, 'module') else model.sr_model\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, sample in enumerate(samples):\n",
    "            lr_img = sample['lr'].unsqueeze(0).to(device)\n",
    "            \n",
    "            # Generate SR\n",
    "            sr_img = sr_model(lr_img)\n",
    "            \n",
    "            # Denormalize for visualization\n",
    "            lr_np = (lr_img[0].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5).clip(0, 1)\n",
    "            sr_np = (sr_img[0].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5).clip(0, 1)\n",
    "            \n",
    "            # Plot LR\n",
    "            axes[idx, 0].imshow(lr_np)\n",
    "            axes[idx, 0].set_title(f'LR Input {lr_img.shape[2]}x{lr_img.shape[3]}')\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            # Plot SR\n",
    "            axes[idx, 1].imshow(sr_np)\n",
    "            axes[idx, 1].set_title(f'SR Output {sr_img.shape[2]}x{sr_img.shape[3]}')\n",
    "            axes[idx, 1].axis('off')\n",
    "            \n",
    "            # Plot difference (enhanced details)\n",
    "            sr_resized = F.interpolate(sr_img, size=lr_img.shape[2:], mode='bilinear', align_corners=False)\n",
    "            diff = torch.abs(sr_resized - lr_img)[0].cpu().numpy().mean(axis=0)\n",
    "            axes[idx, 2].imshow(diff, cmap='hot')\n",
    "            axes[idx, 2].set_title('Enhancement (Difference)')\n",
    "            axes[idx, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    wandb.log({\"sr_enhancement_examples\": wandb.Image(plt)})\n",
    "    plt.savefig('/kaggle/working/sr_enhancement.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def visualize_feature_maps(model, sample_input, device):\n",
    "    \"\"\"Visualize intermediate feature maps from ResNet\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Handle DataParallel wrapper\n",
    "    if hasattr(model, 'module'):\n",
    "        sr_model = model.module.sr_model\n",
    "        backbone = model.module.backbone\n",
    "    else:\n",
    "        sr_model = model.sr_model\n",
    "        backbone = model.backbone\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get SR image\n",
    "        sr_img = sr_model(sample_input)\n",
    "        sr_img = F.interpolate(sr_img, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Extract features at different layers\n",
    "        x = backbone.conv1(sr_img)\n",
    "        x = backbone.bn1(x)\n",
    "        x = backbone.relu(x)\n",
    "        x = backbone.maxpool(x)\n",
    "        \n",
    "        layer1_out = backbone.layer1(x)\n",
    "        layer2_out = backbone.layer2(layer1_out)\n",
    "        layer3_out = backbone.layer3(layer2_out)\n",
    "        layer4_out = backbone.layer4(layer3_out)\n",
    "        \n",
    "        layers = [x, layer1_out, layer2_out, layer3_out, layer4_out]\n",
    "        layer_names = ['Conv1+Pool', 'Layer1', 'Layer2', 'Layer3', 'Layer4']\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Plot input\n",
    "        img_np = (sr_img[0].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5).clip(0, 1)\n",
    "        axes[0].imshow(img_np)\n",
    "        axes[0].set_title('SR Input to ResNet', fontsize=14, fontweight='bold')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Plot feature maps\n",
    "        for idx, (layer_out, name) in enumerate(zip(layers, layer_names)):\n",
    "            # Average across channels\n",
    "            feat_map = layer_out[0].cpu().numpy().mean(axis=0)\n",
    "            im = axes[idx+1].imshow(feat_map, cmap='viridis')\n",
    "            axes[idx+1].set_title(f'{name}\\n{layer_out.shape[1]} channels, {layer_out.shape[2]}x{layer_out.shape[3]}', \n",
    "                                  fontsize=12, fontweight='bold')\n",
    "            axes[idx+1].axis('off')\n",
    "            plt.colorbar(im, ax=axes[idx+1], fraction=0.046)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        wandb.log({\"feature_maps\": wandb.Image(plt)})\n",
    "        plt.savefig('/kaggle/working/feature_maps.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "def plot_roc_curves(y_true, y_pred_probs, num_classes=19):\n",
    "    \"\"\"Plot ROC curves for multi-class classification\"\"\"\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    \n",
    "    # Binarize labels\n",
    "    y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot ROC for each class (show subset)\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    for i in range(min(5, num_classes)):  # Show first 5 classes\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax1.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC={roc_auc:.3f})')\n",
    "    ax1.plot([0, 1], [0, 1], 'k--', lw=2, label='Random')\n",
    "    ax1.set_xlabel('False Positive Rate')\n",
    "    ax1.set_ylabel('True Positive Rate')\n",
    "    ax1.set_title('ROC Curves (First 5 Classes)')\n",
    "    ax1.legend(loc='lower right', fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Compute macro-average ROC\n",
    "    ax2 = plt.subplot(2, 2, 2)\n",
    "    all_fpr = np.unique(np.concatenate([roc_curve(y_true_bin[:, i], y_pred_probs[:, i])[0] \n",
    "                                        for i in range(num_classes)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(num_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "        mean_tpr += np.interp(all_fpr, fpr, tpr)\n",
    "    mean_tpr /= num_classes\n",
    "    macro_auc = auc(all_fpr, mean_tpr)\n",
    "    ax2.plot(all_fpr, mean_tpr, 'b-', lw=3, label=f'Macro-avg (AUC={macro_auc:.3f})')\n",
    "    ax2.plot([0, 1], [0, 1], 'k--', lw=2, label='Random')\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_title('Macro-Average ROC Curve')\n",
    "    ax2.legend(loc='lower right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # AUC distribution\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    aucs = [auc(*roc_curve(y_true_bin[:, i], y_pred_probs[:, i])[:2]) for i in range(num_classes)]\n",
    "    ax3.bar(range(num_classes), aucs, color='steelblue', alpha=0.7, edgecolor='navy')\n",
    "    ax3.axhline(y=np.mean(aucs), color='red', linestyle='--', lw=2, label=f'Mean={np.mean(aucs):.3f}')\n",
    "    ax3.set_xlabel('Class')\n",
    "    ax3.set_ylabel('AUC')\n",
    "    ax3.set_title('Per-Class AUC Distribution')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # AUC statistics\n",
    "    ax4 = plt.subplot(2, 2, 4)\n",
    "    ax4.axis('off')\n",
    "    stats_text = f\"\"\"\n",
    "    ROC-AUC Statistics:\n",
    "    \n",
    "    Macro-Average AUC: {macro_auc:.4f}\n",
    "    Mean AUC: {np.mean(aucs):.4f}\n",
    "    Std AUC: {np.std(aucs):.4f}\n",
    "    Min AUC: {np.min(aucs):.4f} (Class {np.argmin(aucs)})\n",
    "    Max AUC: {np.max(aucs):.4f} (Class {np.argmax(aucs)})\n",
    "    \n",
    "    Classes with AUC > 0.9: {sum(auc > 0.9 for auc in aucs)}/{num_classes}\n",
    "    Classes with AUC > 0.8: {sum(auc > 0.8 for auc in aucs)}/{num_classes}\n",
    "    \"\"\"\n",
    "    ax4.text(0.1, 0.5, stats_text, fontsize=12, verticalalignment='center', \n",
    "             fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    wandb.log({\"roc_curves\": wandb.Image(plt)})\n",
    "    plt.savefig('/kaggle/working/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return macro_auc, aucs\n",
    "\n",
    "def plot_precision_recall_curves(y_true, y_pred_probs, num_classes=19):\n",
    "    \"\"\"Plot Precision-Recall curves\"\"\"\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "    \n",
    "    y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Per-class PR curves (first 5)\n",
    "    for i in range(min(5, num_classes)):\n",
    "        precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "        ap = average_precision_score(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "        axes[0].plot(recall, precision, lw=2, label=f'Class {i} (AP={ap:.3f})')\n",
    "    axes[0].set_xlabel('Recall')\n",
    "    axes[0].set_ylabel('Precision')\n",
    "    axes[0].set_title('Precision-Recall Curves (First 5 Classes)')\n",
    "    axes[0].legend(loc='lower left', fontsize=9)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Average Precision distribution\n",
    "    aps = [average_precision_score(y_true_bin[:, i], y_pred_probs[:, i]) for i in range(num_classes)]\n",
    "    axes[1].bar(range(num_classes), aps, color='coral', alpha=0.7, edgecolor='darkred')\n",
    "    axes[1].axhline(y=np.mean(aps), color='blue', linestyle='--', lw=2, label=f'Mean AP={np.mean(aps):.3f}')\n",
    "    axes[1].set_xlabel('Class')\n",
    "    axes[1].set_ylabel('Average Precision')\n",
    "    axes[1].set_title('Per-Class Average Precision')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    wandb.log({\"precision_recall_curves\": wandb.Image(plt)})\n",
    "    plt.savefig('/kaggle/working/pr_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return np.mean(aps), aps\n",
    "\n",
    "def plot_learning_dynamics(history):\n",
    "    \"\"\"Plot comprehensive learning dynamics\"\"\"\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Loss with smoothing\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    ax1.plot(epochs, history['train_loss'], 'o-', alpha=0.6, label='Train', markersize=4)\n",
    "    ax1.plot(epochs, history['val_loss'], 's-', alpha=0.6, label='Val', markersize=4)\n",
    "    # Add moving average\n",
    "    if len(history['train_loss']) > 5:\n",
    "        train_smooth = np.convolve(history['train_loss'], np.ones(5)/5, mode='valid')\n",
    "        val_smooth = np.convolve(history['val_loss'], np.ones(5)/5, mode='valid')\n",
    "        ax1.plot(range(3, len(train_smooth)+3), train_smooth, 'b-', lw=2, alpha=0.8, label='Train (MA)')\n",
    "        ax1.plot(range(3, len(val_smooth)+3), val_smooth, 'r-', lw=2, alpha=0.8, label='Val (MA)')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Loss Evolution with Moving Average')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy gap\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(epochs, history['train_acc'], 'g-', label='Train', lw=2)\n",
    "    ax2.plot(epochs, history['val_acc'], 'b-', label='Val', lw=2)\n",
    "    gap = np.array(history['train_acc']) - np.array(history['val_acc'])\n",
    "    ax2.fill_between(epochs, history['val_acc'], history['train_acc'], alpha=0.3, color='orange', label='Gap')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title(f'Train-Val Gap (Mean: {gap.mean():.2f}%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1 Score progression\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.plot(epochs, history['val_f1'], 'mo-', lw=2, markersize=6, label='Val F1')\n",
    "    best_f1_epoch = np.argmax(history['val_f1']) + 1\n",
    "    ax3.axvline(x=best_f1_epoch, color='red', linestyle='--', alpha=0.5, label=f'Best at epoch {best_f1_epoch}')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('F1 Score (%)')\n",
    "    ax3.set_title(f'F1 Macro (Best: {max(history[\"val_f1\"]):.2f}%)')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    ax4.plot(epochs, history['lr'], 'r-', lw=2)\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Learning Rate')\n",
    "    ax4.set_title('Learning Rate Schedule')\n",
    "    ax4.set_yscale('log')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss landscape\n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    scatter = ax5.scatter(history['train_loss'], history['val_loss'], \n",
    "                         c=range(len(history['train_loss'])), cmap='viridis', \n",
    "                         s=100, alpha=0.6, edgecolors='black')\n",
    "    ax5.plot([min(history['train_loss']), max(history['train_loss'])], \n",
    "            [min(history['train_loss']), max(history['train_loss'])], \n",
    "            'r--', alpha=0.5, label='y=x')\n",
    "    ax5.set_xlabel('Train Loss')\n",
    "    ax5.set_ylabel('Val Loss')\n",
    "    ax5.set_title('Loss Correlation')\n",
    "    plt.colorbar(scatter, ax=ax5, label='Epoch')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Convergence rate\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    if len(history['val_acc']) > 1:\n",
    "        acc_improvement = np.diff(history['val_acc'])\n",
    "        ax6.bar(range(1, len(acc_improvement)+1), acc_improvement, \n",
    "               color=['green' if x > 0 else 'red' for x in acc_improvement], alpha=0.7)\n",
    "        ax6.axhline(y=0, color='black', linestyle='-', lw=1)\n",
    "        ax6.set_xlabel('Epoch')\n",
    "        ax6.set_ylabel('Accuracy Change (%)')\n",
    "        ax6.set_title('Per-Epoch Accuracy Improvement')\n",
    "        ax6.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Training statistics summary\n",
    "    ax7 = fig.add_subplot(gs[2, :])\n",
    "    ax7.axis('off')\n",
    "    stats = f\"\"\"\n",
    "    Training Statistics Summary:\n",
    "    \n",
    "    Best Validation Accuracy: {max(history['val_acc']):.2f}% (Epoch {np.argmax(history['val_acc'])+1})\n",
    "    Best Validation F1: {max(history['val_f1']):.2f}% (Epoch {np.argmax(history['val_f1'])+1})\n",
    "    Final Train Accuracy: {history['train_acc'][-1]:.2f}%\n",
    "    Final Val Accuracy: {history['val_acc'][-1]:.2f}%\n",
    "    Final Train-Val Gap: {history['train_acc'][-1] - history['val_acc'][-1]:.2f}%\n",
    "    \n",
    "    Loss Reduction: {history['train_loss'][0]:.4f} ‚Üí {history['train_loss'][-1]:.4f} ({(1-history['train_loss'][-1]/history['train_loss'][0])*100:.1f}% decrease)\n",
    "    Accuracy Gain: {history['val_acc'][0]:.2f}% ‚Üí {history['val_acc'][-1]:.2f}% (+{history['val_acc'][-1]-history['val_acc'][0]:.2f}%)\n",
    "    \n",
    "    Learning Rate: {history['lr'][0]:.2e} ‚Üí {history['lr'][-1]:.2e}\n",
    "    Total Epochs Trained: {len(history['train_loss'])}\n",
    "    \"\"\"\n",
    "    ax7.text(0.1, 0.5, stats, fontsize=11, verticalalignment='center', \n",
    "            fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    wandb.log({\"learning_dynamics\": wandb.Image(plt)})\n",
    "    plt.savefig('/kaggle/working/learning_dynamics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(\"‚úì Comprehensive evaluation metrics, EMA & advanced visualizations defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500aee82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING FULL TRAINING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfba18f924c748f5bfcc204ac1169db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/724 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38/2693479398.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     train_loss, train_acc = train_epoch(classifier, train_loader, criterion, \n\u001b[0m\u001b[1;32m     23\u001b[0m                                         optimizer, scaler, device)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_38/3037286883.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, criterion, optimizer, scaler, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mixed_precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 6: Full Training Pipeline with Active Learning\n",
    "# ===============================================================================\n",
    "\n",
    "# Setup with label smoothing and warmup\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
    "optimizer = optim.AdamW(classifier.parameters(), lr=config['lr'], \n",
    "                        weight_decay=config['weight_decay'])\n",
    "\n",
    "# Warmup + Cosine Annealing scheduler\n",
    "warmup_scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, \n",
    "                                               total_iters=config['warmup_epochs'])\n",
    "main_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                                      T_max=config['clf_epochs'] - config['warmup_epochs'],\n",
    "                                                      eta_min=1e-6)\n",
    "scheduler = optim.lr_scheduler.SequentialLR(optimizer, \n",
    "                                            schedulers=[warmup_scheduler, main_scheduler],\n",
    "                                            milestones=[config['warmup_epochs']])\n",
    "\n",
    "scaler = GradScaler() if config['mixed_precision'] else None\n",
    "\n",
    "# Initialize EMA\n",
    "ema = EMA(classifier, decay=config['ema_decay'])\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING OPTIMIZED TRAINING PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üìä Enhancements: Label Smoothing, Warmup LR, EMA, Enhanced Metrics\")\n",
    "print(f\"‚è±Ô∏è  Estimated Time: ~2.5-3 hours for 30 epochs\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Track training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Initial supervised training with enhanced evaluation\n",
    "best_val_acc = 0\n",
    "best_val_f1 = 0\n",
    "\n",
    "for epoch in range(config['clf_epochs']):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['clf_epochs']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(classifier, train_loader, criterion, \n",
    "                                        optimizer, scaler, device)\n",
    "    \n",
    "    # Update EMA\n",
    "    ema.update()\n",
    "    \n",
    "    # Validate with original weights\n",
    "    val_loss, val_acc, val_f1, val_preds, val_labels = evaluate(classifier, val_loader, \n",
    "                                                                 criterion, device)\n",
    "    \n",
    "    # Validate with EMA weights\n",
    "    ema.apply_shadow()\n",
    "    val_loss_ema, val_acc_ema, val_f1_ema, val_preds_ema, val_labels_ema = evaluate(\n",
    "        classifier, val_loader, criterion, device)\n",
    "    ema.restore()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # Use EMA results if better\n",
    "    use_ema = val_acc_ema > val_acc\n",
    "    final_val_acc = val_acc_ema if use_ema else val_acc\n",
    "    final_val_f1 = val_f1_ema if use_ema else val_f1\n",
    "    final_val_loss = val_loss_ema if use_ema else val_loss\n",
    "    final_preds = val_preds_ema if use_ema else val_preds\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(final_val_loss)\n",
    "    history['val_acc'].append(final_val_acc)\n",
    "    history['val_f1'].append(final_val_f1)\n",
    "    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    # Compute per-class metrics\n",
    "    precision, recall, f1_per_class, support = compute_per_class_metrics(\n",
    "        val_labels_ema if use_ema else val_labels, final_preds, config['num_classes']\n",
    "    )\n",
    "    \n",
    "    # Log metrics\n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'train/loss': train_loss,\n",
    "        'train/accuracy': train_acc,\n",
    "        'val/loss': final_val_loss,\n",
    "        'val/accuracy': final_val_acc,\n",
    "        'val/f1_macro': final_val_f1,\n",
    "        'val/precision_macro': precision.mean() * 100,\n",
    "        'val/recall_macro': recall.mean() * 100,\n",
    "        'val_ema/accuracy': val_acc_ema,\n",
    "        'val_ema/f1_macro': val_f1_ema,\n",
    "        'lr': optimizer.param_groups[0]['lr'],\n",
    "        'epoch_time': time.time() - epoch_start\n",
    "    })\n",
    "    \n",
    "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val   - Loss: {final_val_loss:.4f}, Acc: {final_val_acc:.2f}%, F1: {final_val_f1:.2f}%\")\n",
    "    if use_ema:\n",
    "        print(f\"        (Using EMA weights - {val_acc_ema:.2f}% vs {val_acc:.2f}%)\")\n",
    "    print(f\"        Precision: {precision.mean()*100:.2f}%, Recall: {recall.mean()*100:.2f}%\")\n",
    "    print(f\"        LR: {optimizer.param_groups[0]['lr']:.2e}, Time: {time.time()-epoch_start:.1f}s\")\n",
    "    \n",
    "    # Save best model (both standard and EMA)\n",
    "    if final_val_acc > best_val_acc:\n",
    "        best_val_acc = final_val_acc\n",
    "        best_val_f1 = final_val_f1\n",
    "        if use_ema:\n",
    "            ema.apply_shadow()\n",
    "            torch.save(classifier.state_dict(), '/kaggle/working/best_classifier.pth')\n",
    "            ema.restore()\n",
    "        else:\n",
    "            torch.save(classifier.state_dict(), '/kaggle/working/best_classifier.pth')\n",
    "        print(f\"‚úì Saved best model (acc: {best_val_acc:.2f}%, F1: {best_val_f1:.2f}%)\")\n",
    "    \n",
    "    # Comprehensive visualizations based on viz_frequency\n",
    "    viz_freq = config.get('viz_frequency', 5)\n",
    "    is_viz_epoch = (epoch + 1) % viz_freq == 0 or (epoch + 1) in [1, 5, 10, 25, config['clf_epochs']]\n",
    "    \n",
    "    if is_viz_epoch:\n",
    "        print(f\"\\nüìä Generating visualizations for epoch {epoch+1}...\")\n",
    "        \n",
    "        # Standard visualizations\n",
    "        plot_confusion_matrix(val_labels_ema if use_ema else val_labels, final_preds, epoch + 1)\n",
    "        plot_per_class_performance(precision, recall, f1_per_class, support)\n",
    "        plot_training_curves(history)\n",
    "        \n",
    "        # SR Enhancement examples\n",
    "        if config.get('save_sr_examples', True):\n",
    "            print(\"  ‚Üí SR enhancement comparison...\")\n",
    "            visualize_sr_enhancement(classifier, train_dataset, device, num_samples=6)\n",
    "        \n",
    "        # Feature maps\n",
    "        if config.get('save_feature_maps', True) and (epoch + 1) % (viz_freq * 2) == 0:\n",
    "            print(\"  ‚Üí Feature map extraction...\")\n",
    "            sample_batch = next(iter(val_loader))\n",
    "            sample_input = sample_batch['lr'][:1].to(device)\n",
    "            visualize_feature_maps(classifier, sample_input, device)\n",
    "        \n",
    "        # Learning dynamics (after epoch 2)\n",
    "        if epoch > 1:\n",
    "            print(\"  ‚Üí Learning dynamics analysis...\")\n",
    "            plot_learning_dynamics(history)\n",
    "        \n",
    "        print(\"  ‚úì Visualizations saved\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    if (epoch + 1) % 3 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"TRAINING COMPLETE\")\n",
    "print(f\"Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"Best Val F1 Score: {best_val_f1:.2f}%\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Final comprehensive evaluation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL EVALUATION WITH BEST MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load best model\n",
    "classifier.load_state_dict(torch.load('/kaggle/working/best_classifier.pth'))\n",
    "val_loss, val_acc, val_f1, val_preds, val_labels = evaluate(classifier, val_loader, \n",
    "                                                             criterion, device)\n",
    "\n",
    "# Compute all metrics\n",
    "precision, recall, f1_per_class, support = compute_per_class_metrics(\n",
    "    val_labels, val_preds, config['num_classes']\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Overall Metrics:\")\n",
    "print(f\"  Accuracy:  {val_acc:.2f}%\")\n",
    "print(f\"  F1 (Macro): {val_f1:.2f}%\")\n",
    "print(f\"  Precision: {precision.mean()*100:.2f}%\")\n",
    "print(f\"  Recall:    {recall.mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìà Per-Class Statistics:\")\n",
    "print(f\"  Best F1 Class:   Class {f1_per_class.argmax()} ({f1_per_class.max()*100:.2f}%)\") \n",
    "print(f\"  Worst F1 Class:  Class {f1_per_class.argmin()} ({f1_per_class.min()*100:.2f}%)\")\n",
    "print(f\"  F1 Std Dev:      {f1_per_class.std()*100:.2f}%\")\n",
    "\n",
    "# Generate final visualizations\n",
    "print(\"\\nüìà Generating comprehensive final visualizations...\")\n",
    "\n",
    "# 1. Confusion matrix\n",
    "print(\"  ‚Üí Confusion matrix...\")\n",
    "plot_confusion_matrix(val_labels, val_preds, 'FINAL')\n",
    "\n",
    "# 2. Per-class performance\n",
    "print(\"  ‚Üí Per-class performance bars...\")\n",
    "plot_per_class_performance(precision, recall, f1_per_class, support)\n",
    "\n",
    "# 3. Training curves\n",
    "print(\"  ‚Üí Training progression curves...\")\n",
    "plot_training_curves(history)\n",
    "\n",
    "# 4. Learning dynamics\n",
    "print(\"  ‚Üí Learning dynamics analysis...\")\n",
    "plot_learning_dynamics(history)\n",
    "\n",
    "# 5. Get prediction probabilities for ROC/PR curves\n",
    "print(\"  ‚Üí Computing prediction probabilities...\")\n",
    "classifier.eval()\n",
    "all_probs = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc='Computing probabilities'):\n",
    "        lr_imgs = batch['lr'].to(device)\n",
    "        outputs = classifier(lr_imgs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# 6. ROC curves\n",
    "print(\"  ‚Üí ROC curves...\")\n",
    "macro_auc, class_aucs = plot_roc_curves(val_labels, all_probs, num_classes=config['num_classes'])\n",
    "\n",
    "# 7. Precision-Recall curves\n",
    "print(\"  ‚Üí Precision-Recall curves...\")\n",
    "mean_ap, class_aps = plot_precision_recall_curves(val_labels, all_probs, num_classes=config['num_classes'])\n",
    "\n",
    "# 8. SR enhancement examples\n",
    "print(\"  ‚Üí Final SR enhancement examples...\")\n",
    "visualize_sr_enhancement(classifier, val_dataset, device, num_samples=8)\n",
    "\n",
    "# 9. Feature maps\n",
    "print(\"  ‚Üí Final feature map visualization...\")\n",
    "sample_batch = next(iter(val_loader))\n",
    "sample_input = sample_batch['lr'][:1].to(device)\n",
    "visualize_feature_maps(classifier, sample_input, device)\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nüìã Detailed Classification Report:\")\n",
    "print(classification_report(val_labels, val_preds, digits=4))\n",
    "\n",
    "# Save classification report\n",
    "report = classification_report(val_labels, val_preds, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv('/kaggle/working/classification_report.csv')\n",
    "print(\"\\n‚úì Saved classification report to classification_report.csv\")\n",
    "\n",
    "# Log final comprehensive metrics\n",
    "wandb.log({\n",
    "    'final/accuracy': val_acc,\n",
    "    'final/f1_macro': val_f1,\n",
    "    'final/roc_auc_macro': macro_auc,\n",
    "    'final/mean_average_precision': mean_ap,\n",
    "    'final/training_hours': (time.time() - start_time) / 3600,\n",
    "    'final/best_accuracy': best_val_acc,\n",
    "    'final/best_f1': best_val_f1\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE EVALUATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üìä Final Metrics Summary:\")\n",
    "print(f\"  Validation Accuracy:     {val_acc:.2f}%\")\n",
    "print(f\"  Validation F1 (Macro):   {val_f1:.2f}%\")\n",
    "print(f\"  ROC-AUC (Macro):         {macro_auc:.4f}\")\n",
    "print(f\"  Mean Average Precision:  {mean_ap:.4f}\")\n",
    "print(f\"  Training Time:           {(time.time() - start_time)/3600:.2f} hours\")\n",
    "print(f\"  Best Accuracy Achieved:  {best_val_acc:.2f}%\")\n",
    "print(f\"  Best F1 Achieved:        {best_val_f1:.2f}%\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "wandb.finish()\n",
    "print(\"\\n‚úÖ Training pipeline complete with comprehensive visual evaluation!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
