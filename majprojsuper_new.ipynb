{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a53730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m432.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/2.2 GB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m432.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/7.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/89.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.0+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.0+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/22.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhegdesudarshan\u001b[0m (\u001b[33mhegdesudarshan-hegde\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhegdesudarshan\u001b[0m (\u001b[33mhegdesudarshan-hegde\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ WandB authenticated\n",
      "\n",
      "ğŸš€ Device: cuda | GPUs: 2\n",
      "   GPU 0: Tesla T4\n",
      "   GPU 1: Tesla T4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20251124_162133-lg1kdi52</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification/runs/lg1kdi52' target=\"_blank\">SR-ResNet-AL-20251124-162133</a></strong> to <a href='https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification' target=\"_blank\">https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification/runs/lg1kdi52' target=\"_blank\">https://wandb.ai/hegdesudarshan-hegde/SR-ResNet-AL-Classification/runs/lg1kdi52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Setup complete!\n",
      "Config: {'dataset_size': 50000, 'num_classes': 19, 'sr_model_path': '/kaggle/input/sr-model/pytorch/default/3/generator_ensemble.pth', 'lr_size': 32, 'hr_size': 128, 'clf_epochs': 20, 'batch_size': 32, 'lr': 0.0001, 'weight_decay': 0.0001, 'al_cycles': 4, 'al_epochs_per_cycle': 10, 'initial_labeled_ratio': 0.1, 'query_size_ratio': 0.1, 'num_workers': 4, 'pin_memory': True, 'mixed_precision': True}\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 1: Dependencies & WandB Setup\n",
    "# ===============================================================================\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install -q torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q wandb scikit-learn matplotlib seaborn tqdm Pillow rasterio pandas\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import rasterio\n",
    "import wandb\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# WandB Login\n",
    "wandb.login(key=\"5424a3d65aac1662f5be82d4439aaac35046689e\")\n",
    "print(\"âœ“ WandB authenticated\")\n",
    "\n",
    "# Device Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(f\"\\nğŸš€ Device: {device} | GPUs: {gpu_count}\")\n",
    "if gpu_count > 0:\n",
    "    for i in range(gpu_count):\n",
    "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# Config\n",
    "config = {\n",
    "    # Dataset\n",
    "    'dataset_size': 50000,  # Subset for 12h constraint\n",
    "    'num_classes': 19,      # BigEarthNet-19 classes\n",
    "    \n",
    "    # SR Model\n",
    "    'sr_model_path': '/kaggle/input/sr-model/pytorch/default/3/generator_ensemble.pth',\n",
    "    'lr_size': 32,          # LR input size\n",
    "    'hr_size': 128,         # HR output size (32*4)\n",
    "    \n",
    "    # Classifier Training\n",
    "    'clf_epochs': 20,\n",
    "    'batch_size': 32,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    \n",
    "    # Active Learning\n",
    "    'al_cycles': 4,\n",
    "    'al_epochs_per_cycle': 10,\n",
    "    'initial_labeled_ratio': 0.1,\n",
    "    'query_size_ratio': 0.1,\n",
    "    \n",
    "    # Training\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True,\n",
    "    'mixed_precision': True,\n",
    "}\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(\n",
    "    project=\"SR-ResNet-AL-Classification\",\n",
    "    config=config,\n",
    "    name=f\"SR-ResNet-AL-{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Setup complete!\")\n",
    "print(f\"Config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ebcd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained SR model...\n",
      "âœ“ SR Model loaded: torch.Size([1, 3, 32, 32]) â†’ torch.Size([1, 3, 256, 256])\n",
      "  Parameters: 9.77M\n",
      "\n",
      "âœ“ SR model ready for inference!\n",
      "âœ“ SR Model loaded: torch.Size([1, 3, 32, 32]) â†’ torch.Size([1, 3, 256, 256])\n",
      "  Parameters: 9.77M\n",
      "\n",
      "âœ“ SR model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 2: Load Pre-trained SR Model (EXACT ARCHITECTURE FROM CHECKPOINT)\n",
    "# ===============================================================================\n",
    "\n",
    "class RFB(nn.Module):\n",
    "    \"\"\"Receptive Field Block - EXACT match to checkpoint\"\"\"\n",
    "    def __init__(self, in_channels=64):\n",
    "        super().__init__()\n",
    "        # Branch 1: AvgPool(3) + Conv + ReLU + Conv\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, 16, 1, 1, 0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 16, 3, 1, padding=1, dilation=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Branch 2: AvgPool(5) + Conv + ReLU + Conv\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.AvgPool2d(5, stride=1, padding=2),\n",
    "            nn.Conv2d(in_channels, 24, 1, 1, 0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(24, 24, 3, 1, padding=2, dilation=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Branch 3: AvgPool(7) + Conv + ReLU + Conv\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(7, stride=1, padding=3),\n",
    "            nn.Conv2d(in_channels, 24, 1, 1, 0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(24, 24, 3, 1, padding=3, dilation=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Changed to match checkpoint: conv_concat instead of conv\n",
    "        self.conv_concat = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 1, 1, 0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b1 = self.branch1(x)\n",
    "        b2 = self.branch2(x)\n",
    "        b3 = self.branch3(x)\n",
    "        out = torch.cat([b1, b2, b3], 1)\n",
    "        return self.conv_concat(out) * 0.2 + x\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    \"\"\"Dense Block with 5 conv layers - MODIFIED channel counts to match checkpoint\"\"\"\n",
    "    def __init__(self, nf=64):\n",
    "        super().__init__()\n",
    "        # Changed: nf=64 in Generator, but DenseBlock uses nf_internal=32\n",
    "        nf_internal = 32\n",
    "        self.conv1 = nn.Conv2d(nf, nf_internal, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(nf + nf_internal, nf_internal, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(nf + nf_internal*2, nf_internal, 3, 1, 1)\n",
    "        self.conv4 = nn.Conv2d(nf + nf_internal*3, nf_internal, 3, 1, 1)\n",
    "        self.conv5 = nn.Conv2d(nf + nf_internal*4, nf, 3, 1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = F.relu(self.conv2(torch.cat([x, x1], 1)))\n",
    "        x3 = F.relu(self.conv3(torch.cat([x, x1, x2], 1)))\n",
    "        x4 = F.relu(self.conv4(torch.cat([x, x1, x2, x3], 1)))\n",
    "        x5 = self.conv5(torch.cat([x, x1, x2, x3, x4], 1))\n",
    "        return x5 * 0.2 + x\n",
    "\n",
    "class RRDB(nn.Module):\n",
    "    \"\"\"Residual-in-Residual Dense Block (3 DenseBlocks)\"\"\"\n",
    "    def __init__(self, nf=64):\n",
    "        super().__init__()\n",
    "        self.db1 = DenseBlock(nf)\n",
    "        self.db2 = DenseBlock(nf)\n",
    "        self.db3 = DenseBlock(nf)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.db3(self.db2(self.db1(x)))\n",
    "        return out * 0.2 + x\n",
    "\n",
    "class RRFDB(nn.Module):\n",
    "    \"\"\"Residual RFB Dense Block - MODIFIED to match checkpoint structure\"\"\"\n",
    "    def __init__(self, nf=64):\n",
    "        super().__init__()\n",
    "        # Changed: Use named attributes instead of ModuleList to match checkpoint keys\n",
    "        self.rfb1 = RFB(nf)\n",
    "        self.rfb2 = RFB(nf)\n",
    "        self.rfb3 = RFB(nf)\n",
    "        self.rfb4 = RFB(nf)\n",
    "        self.rfb5 = RFB(nf)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.rfb1(x)\n",
    "        out = self.rfb2(out)\n",
    "        out = self.rfb3(out)\n",
    "        out = self.rfb4(out)\n",
    "        out = self.rfb5(out)\n",
    "        return out * 0.2 + x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator: 12 RRDB + 6 RRFDB + 8x upscale - EXACT architecture from checkpoint\"\"\"\n",
    "    def __init__(self, num_rrdb=12, num_rrfdb=6, nf=64):\n",
    "        super().__init__()\n",
    "        self.conv_first = nn.Conv2d(3, nf, 3, 1, 1)\n",
    "        \n",
    "        # Trunk A: 12 RRDB blocks\n",
    "        self.trunk_a = nn.Sequential(*[RRDB(nf) for _ in range(num_rrdb)])\n",
    "        \n",
    "        # Trunk RFB: 6 RRFDB blocks\n",
    "        self.trunk_rfb = nn.Sequential(*[RRFDB(nf) for _ in range(num_rrfdb)])\n",
    "        \n",
    "        # RFB upsampling\n",
    "        self.rfb_up = RFB(nf)\n",
    "        \n",
    "        # 8x upscaling (3 PixelShuffle layers: 2x each = 2^3 = 8x)\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(nf, nf*4, 3, 1, 1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(nf, nf*4, 3, 1, 1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(nf, nf*4, 3, 1, 1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Changed to match checkpoint: Sequential with conv_final layers\n",
    "        self.conv_final = nn.Sequential(\n",
    "            nn.Conv2d(nf, nf, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(nf, 3, 3, 1, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feat = self.conv_first(x)\n",
    "        trunk_a_out = self.trunk_a(feat)\n",
    "        trunk_rfb_out = self.trunk_rfb(trunk_a_out)\n",
    "        rfb_up_out = self.rfb_up(trunk_rfb_out)\n",
    "        up = self.upsample(rfb_up_out + feat)\n",
    "        return torch.tanh(self.conv_final(up))\n",
    "\n",
    "# Load Pre-trained SR Model\n",
    "print(\"Loading pre-trained SR model...\")\n",
    "sr_model = Generator(num_rrdb=12, num_rrfdb=6, nf=64).to(device)\n",
    "\n",
    "try:\n",
    "    state_dict = torch.load(config['sr_model_path'], map_location=device)\n",
    "    sr_model.load_state_dict(state_dict)\n",
    "    sr_model.eval()\n",
    "    \n",
    "    # Test SR model\n",
    "    with torch.no_grad():\n",
    "        test_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "        test_output = sr_model(test_input)\n",
    "        print(f\"âœ“ SR Model loaded: {test_input.shape} â†’ {test_output.shape}\")\n",
    "        \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in sr_model.parameters())\n",
    "    print(f\"  Parameters: {total_params/1e6:.2f}M\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading SR model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "# Freeze SR model (no training needed)\n",
    "for param in sr_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"\\nâœ“ SR model ready for inference!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f95c772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BigEarthNet dataset...\n",
      "Found 347244 band files\n",
      "Found 347244 band files\n",
      "Valid RGB patches: 28937\n",
      "Warning: metadata.parquet not found, using dummy labels\n",
      "Split: 23149 train, 5788 val\n",
      "\n",
      "âœ“ Dataset loaded!\n",
      "  Train batches: 724\n",
      "  Val batches: 91\n",
      "Valid RGB patches: 28937\n",
      "Warning: metadata.parquet not found, using dummy labels\n",
      "Split: 23149 train, 5788 val\n",
      "\n",
      "âœ“ Dataset loaded!\n",
      "  Train batches: 724\n",
      "  Val batches: 91\n",
      "\n",
      "Sample batch shapes:\n",
      "  LR: torch.Size([32, 3, 32, 32])\n",
      "  Label: torch.Size([32])\n",
      "\n",
      "Sample batch shapes:\n",
      "  LR: torch.Size([32, 3, 32, 32])\n",
      "  Label: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 3: Dataset Loading (BigEarthNet)\n",
    "# ===============================================================================\n",
    "\n",
    "class BigEarthNetDataset(Dataset):\n",
    "    \"\"\"BigEarthNet dataset with SR preprocessing\"\"\"\n",
    "    def __init__(self, root_path, patch_ids, patch_to_bands, patch_to_label, \n",
    "                 sr_model=None, phase='train'):\n",
    "        self.root_path = root_path\n",
    "        self.patch_ids = patch_ids\n",
    "        self.patch_to_bands = patch_to_bands\n",
    "        self.patch_to_label = patch_to_label\n",
    "        self.sr_model = sr_model\n",
    "        self.phase = phase\n",
    "        \n",
    "        # Transforms\n",
    "        if phase == 'train':\n",
    "            self.spatial_aug = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(90)\n",
    "            ])\n",
    "        else:\n",
    "            self.spatial_aug = None\n",
    "            \n",
    "        self.to_tensor = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.patch_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patch_id = self.patch_ids[idx]\n",
    "        bands = self.patch_to_bands[patch_id]\n",
    "        \n",
    "        try:\n",
    "            # Load RGB bands (B04=Red, B03=Green, B02=Blue)\n",
    "            b02 = rasterio.open(bands['02']).read(1).astype(np.float32) / 10000.0\n",
    "            b03 = rasterio.open(bands['03']).read(1).astype(np.float32) / 10000.0\n",
    "            b04 = rasterio.open(bands['04']).read(1).astype(np.float32) / 10000.0\n",
    "            \n",
    "            # Stack to RGB (120x120)\n",
    "            hr_np = np.stack([b04, b03, b02], axis=-1)\n",
    "            hr_np = np.clip(hr_np, 0, 1)\n",
    "            \n",
    "            # Convert to PIL for augmentation\n",
    "            hr_pil = Image.fromarray((hr_np * 255).astype(np.uint8))\n",
    "            \n",
    "            # Apply spatial augmentation\n",
    "            if self.spatial_aug:\n",
    "                hr_pil = self.spatial_aug(hr_pil)\n",
    "            \n",
    "            # Resize to 32x32 for LR input\n",
    "            lr_pil = hr_pil.resize((32, 32), Image.BICUBIC)\n",
    "            \n",
    "            # To tensor\n",
    "            lr_tensor = self.to_tensor(lr_pil)\n",
    "            \n",
    "            # Get label (multi-hot â†’ single label via argmax)\n",
    "            label_multihot = self.patch_to_label.get(patch_id, torch.zeros(config['num_classes']))\n",
    "            label = torch.argmax(label_multihot).long()\n",
    "            \n",
    "            return {\n",
    "                'lr': lr_tensor,\n",
    "                'label': label,\n",
    "                'patch_id': patch_id\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Return black dummy on error\n",
    "            print(f\"Error loading {patch_id}: {e}\")\n",
    "            return {\n",
    "                'lr': torch.zeros(3, 32, 32),\n",
    "                'label': torch.tensor(0, dtype=torch.long),\n",
    "                'patch_id': patch_id\n",
    "            }\n",
    "\n",
    "# Load BigEarthNet metadata\n",
    "print(\"Loading BigEarthNet dataset...\")\n",
    "image_root_path = '/kaggle/input/bigearthnetv2-s2-4/'\n",
    "\n",
    "# Find all TIF files\n",
    "import glob\n",
    "all_tif_paths = glob.glob(os.path.join(image_root_path, '**/*.tif'), recursive=True)\n",
    "print(f\"Found {len(all_tif_paths)} band files\")\n",
    "\n",
    "# Group by patch ID\n",
    "patch_to_bands = {}\n",
    "for path in all_tif_paths:\n",
    "    fname = os.path.basename(path)\n",
    "    if '_B' in fname:\n",
    "        patch_id = '_'.join(fname.split('_B')[:-1])\n",
    "        band = fname.split('_B')[-1].split('.')[0]\n",
    "        if patch_id not in patch_to_bands:\n",
    "            patch_to_bands[patch_id] = {}\n",
    "        patch_to_bands[patch_id][band] = path\n",
    "\n",
    "# Filter patches with RGB bands\n",
    "valid_patches = [pid for pid, bands in patch_to_bands.items() \n",
    "                 if all(b in bands for b in ['02', '03', '04'])]\n",
    "valid_patches = valid_patches[:config['dataset_size']]\n",
    "print(f\"Valid RGB patches: {len(valid_patches)}\")\n",
    "\n",
    "# Load labels from metadata\n",
    "metadata_path = os.path.join(image_root_path, 'metadata.parquet')\n",
    "if os.path.exists(metadata_path):\n",
    "    df = pd.read_parquet(metadata_path)\n",
    "    patch_to_label = {}\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row['patch_id']\n",
    "        labels_list = row['labels'] if isinstance(row['labels'], list) else []\n",
    "        multi_hot = torch.zeros(config['num_classes'])\n",
    "        for lbl in labels_list:\n",
    "            if 0 <= lbl < config['num_classes']:\n",
    "                multi_hot[lbl] = 1.0\n",
    "        if pid in valid_patches:\n",
    "            patch_to_label[pid] = multi_hot\n",
    "    print(f\"Loaded labels for {len(patch_to_label)} patches\")\n",
    "else:\n",
    "    print(\"Warning: metadata.parquet not found, using dummy labels\")\n",
    "    patch_to_label = {pid: torch.zeros(config['num_classes']) for pid in valid_patches}\n",
    "\n",
    "# Train/Val split\n",
    "train_ids, val_ids = train_test_split(valid_patches, test_size=0.2, random_state=42)\n",
    "print(f\"Split: {len(train_ids)} train, {len(val_ids)} val\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BigEarthNetDataset(image_root_path, train_ids, patch_to_bands, \n",
    "                                   patch_to_label, sr_model, phase='train')\n",
    "val_dataset = BigEarthNetDataset(image_root_path, val_ids, patch_to_bands, \n",
    "                                 patch_to_label, sr_model, phase='val')\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], \n",
    "                         shuffle=True, num_workers=config['num_workers'], \n",
    "                         pin_memory=config['pin_memory'])\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size']*2, \n",
    "                       shuffle=False, num_workers=config['num_workers'], \n",
    "                       pin_memory=config['pin_memory'])\n",
    "\n",
    "print(\"\\nâœ“ Dataset loaded!\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Test batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "print(f\"  LR: {sample_batch['lr'].shape}\")\n",
    "print(f\"  Label: {sample_batch['label'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f25374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# CELL 3.5: GPU Memory Cleanup (Run this if you encounter CUDA errors)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"Cleaning up GPU memory...\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Reset CUDA device if needed\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\"âœ“ GPU memory cleaned\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        mem_allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "        mem_reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "        print(f\"  GPU {i}: {mem_allocated:.2f}GB allocated, {mem_reserved:.2f}GB reserved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SR-Enhanced ResNet50 Classifier...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: misaligned address\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38/2679726534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Create classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating SR-Enhanced ResNet50 Classifier...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSREnhancedClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgpu_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: misaligned address\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CELL 4: ResNet Classifier Definition\n",
    "# ===============================================================================\n",
    "\n",
    "class SREnhancedClassifier(nn.Module):\n",
    "    \"\"\"ResNet50-based classifier that processes SR-enhanced images\"\"\"\n",
    "    def __init__(self, num_classes, sr_model, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.sr_model = sr_model  # Frozen SR model\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        if pretrained:\n",
    "            weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "            self.backbone = resnet50(weights=weights)\n",
    "        else:\n",
    "            self.backbone = resnet50(weights=None)\n",
    "        \n",
    "        # Replace final FC layer\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, lr_images):\n",
    "        # Step 1: SR enhancement (frozen) - 32x32 â†’ 256x256\n",
    "        with torch.no_grad():\n",
    "            sr_images = self.sr_model(lr_images)\n",
    "            # Resize 256x256 â†’ 224x224 for ResNet50\n",
    "            sr_images = F.interpolate(sr_images, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Step 2: ResNet classification\n",
    "        x = self.backbone.conv1(sr_images)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "        \n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "        \n",
    "        x = self.backbone.avgpool(x)\n",
    "        features = torch.flatten(x, 1)\n",
    "        features = self.dropout(features)\n",
    "        output = self.backbone.fc(features)\n",
    "        return output\n",
    "    \n",
    "    def get_features(self, lr_images):\n",
    "        \"\"\"Extract features for active learning\"\"\"\n",
    "        with torch.no_grad():\n",
    "            sr_images = self.sr_model(lr_images)\n",
    "            sr_images = F.interpolate(sr_images, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "            \n",
    "            x = self.backbone.conv1(sr_images)\n",
    "            x = self.backbone.bn1(x)\n",
    "            x = self.backbone.relu(x)\n",
    "            x = self.backbone.maxpool(x)\n",
    "            \n",
    "            x = self.backbone.layer1(x)\n",
    "            x = self.backbone.layer2(x)\n",
    "            x = self.backbone.layer3(x)\n",
    "            x = self.backbone.layer4(x)\n",
    "            \n",
    "            x = self.backbone.avgpool(x)\n",
    "            return torch.flatten(x, 1)\n",
    "\n",
    "# Create classifier with error handling\n",
    "print(\"Creating SR-Enhanced ResNet50 Classifier...\")\n",
    "\n",
    "try:\n",
    "    # Clean GPU memory before creating model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Create classifier on CPU first\n",
    "    classifier = SREnhancedClassifier(config['num_classes'], sr_model, pretrained=True)\n",
    "    \n",
    "    # Move to GPU carefully\n",
    "    classifier = classifier.to(device)\n",
    "    print(\"âœ“ Classifier moved to GPU\")\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    if \"CUDA\" in str(e):\n",
    "        print(f\"âš  CUDA Error: {e}\")\n",
    "        print(\"Attempting recovery: Restarting kernel may help\")\n",
    "        print(\"Run the memory cleanup cell (Cell 3.5) and try again\")\n",
    "        raise\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "if gpu_count > 1:\n",
    "    classifier = nn.DataParallel(classifier)\n",
    "    print(f\"  Using DataParallel across {gpu_count} GPUs\")\n",
    "\n",
    "# Count parameters\n",
    "trainable_params = sum(p.numel() for p in classifier.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in classifier.parameters())\n",
    "print(f\"\\nâœ“ Classifier created\")\n",
    "print(f\"  Total parameters: {total_params/1e6:.2f}M\")\n",
    "print(f\"  Trainable parameters: {trainable_params/1e6:.2f}M\")\n",
    "\n",
    "# Test forward pass\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        test_lr = torch.randn(2, 3, 32, 32).to(device)\n",
    "        test_output = classifier(test_lr)\n",
    "        print(f\"\\nTest forward pass: {test_lr.shape} â†’ {test_output.shape}\")\n",
    "        print(f\"Output range: [{test_output.min():.3f}, {test_output.max():.3f}]\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"âš  Test forward pass failed: {e}\")\n",
    "    print(\"This may indicate GPU memory issues. Try restarting the kernel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# CELL 5: Training & Evaluation Functions\n",
    "# ===============================================================================\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, scaler, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for batch in pbar:\n",
    "        lr_imgs = batch['lr'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if config['mixed_precision']:\n",
    "            with autocast():\n",
    "                outputs = model(lr_imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(lr_imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * lr_imgs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'acc': f\"{100.*correct/total:.2f}%\"\n",
    "        })\n",
    "    \n",
    "    return total_loss / total, 100. * correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            lr_imgs = batch['lr'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            if config['mixed_precision']:\n",
    "                with autocast():\n",
    "                    outputs = model(lr_imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            else:\n",
    "                outputs = model(lr_imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item() * lr_imgs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro') * 100\n",
    "    avg_loss = total_loss / len(all_labels)\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, epoch):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - Epoch {epoch}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Log to wandb\n",
    "    wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
    "    plt.close()\n",
    "\n",
    "print(\"âœ“ Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500aee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# CELL 6: Full Training Pipeline with Active Learning\n",
    "# ===============================================================================\n",
    "\n",
    "# Setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(classifier.parameters(), lr=config['lr'], \n",
    "                        weight_decay=config['weight_decay'])\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['clf_epochs'])\n",
    "scaler = GradScaler() if config['mixed_precision'] else None\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING FULL TRAINING PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initial supervised training\n",
    "best_val_acc = 0\n",
    "for epoch in range(config['clf_epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['clf_epochs']}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(classifier, train_loader, criterion, \n",
    "                                        optimizer, scaler, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_f1, val_preds, val_labels = evaluate(classifier, val_loader, \n",
    "                                                                 criterion, device)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # Log metrics\n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'train/loss': train_loss,\n",
    "        'train/accuracy': train_acc,\n",
    "        'val/loss': val_loss,\n",
    "        'val/accuracy': val_acc,\n",
    "        'val/f1_macro': val_f1,\n",
    "        'lr': optimizer.param_groups[0]['lr']\n",
    "    })\n",
    "    \n",
    "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, F1: {val_f1:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(classifier.state_dict(), '/kaggle/working/best_classifier.pth')\n",
    "        print(f\"âœ“ Saved best model (acc: {best_val_acc:.2f}%)\")\n",
    "    \n",
    "    # Plot confusion matrix every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        plot_confusion_matrix(val_labels, val_preds, epoch + 1)\n",
    "    \n",
    "    # Memory cleanup\n",
    "    if (epoch + 1) % 3 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"TRAINING COMPLETE - Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
